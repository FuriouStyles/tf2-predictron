{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictron-RUL-C-MAPSS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lk196J1yW_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Da2Q6OyhVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = ['unit', 'cycle', 'op_set_1', 'op_set_2', 'op_set_3',\n",
        "             'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6',\n",
        "             'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12', \n",
        "             'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17',\n",
        "             'sensor18', 'sensor19', 'sensor20', 'sensor21']\n",
        "\n",
        "\n",
        "data = pd.read_csv('train_FD001.txt',\n",
        "                   delimiter=' ',\n",
        "                   names=col_names,\n",
        "                   index_col=False,\n",
        "                   skipinitialspace=True\n",
        "                   )\n",
        "\n",
        "data.set_index(['unit', 'cycle'], inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ex7E92qMtki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "496f9d59-9791-41b8-aa49-e82577fce4c1"
      },
      "source": [
        "data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>op_set_1</th>\n",
              "      <th>op_set_2</th>\n",
              "      <th>op_set_3</th>\n",
              "      <th>sensor1</th>\n",
              "      <th>sensor2</th>\n",
              "      <th>sensor3</th>\n",
              "      <th>sensor4</th>\n",
              "      <th>sensor5</th>\n",
              "      <th>sensor6</th>\n",
              "      <th>sensor7</th>\n",
              "      <th>sensor8</th>\n",
              "      <th>sensor9</th>\n",
              "      <th>sensor10</th>\n",
              "      <th>sensor11</th>\n",
              "      <th>sensor12</th>\n",
              "      <th>sensor13</th>\n",
              "      <th>sensor14</th>\n",
              "      <th>sensor15</th>\n",
              "      <th>sensor16</th>\n",
              "      <th>sensor17</th>\n",
              "      <th>sensor18</th>\n",
              "      <th>sensor19</th>\n",
              "      <th>sensor20</th>\n",
              "      <th>sensor21</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unit</th>\n",
              "      <th>cycle</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th>1</th>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">100</th>\n",
              "      <th>196</th>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>551.43</td>\n",
              "      <td>2388.19</td>\n",
              "      <td>9065.52</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.07</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>550.86</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>9065.11</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.04</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>550.94</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>9065.90</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.09</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>550.68</td>\n",
              "      <td>2388.25</td>\n",
              "      <td>9073.72</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.39</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>550.79</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>9061.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.20</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            op_set_1  op_set_2  op_set_3  ...  sensor19  sensor20  sensor21\n",
              "unit cycle                                ...                              \n",
              "1    1       -0.0007   -0.0004     100.0  ...     100.0     39.06   23.4190\n",
              "     2        0.0019   -0.0003     100.0  ...     100.0     39.00   23.4236\n",
              "     3       -0.0043    0.0003     100.0  ...     100.0     38.95   23.3442\n",
              "     4        0.0007    0.0000     100.0  ...     100.0     38.88   23.3739\n",
              "     5       -0.0019   -0.0002     100.0  ...     100.0     38.90   23.4044\n",
              "...              ...       ...       ...  ...       ...       ...       ...\n",
              "100  196     -0.0004   -0.0003     100.0  ...     100.0     38.49   22.9735\n",
              "     197     -0.0016   -0.0005     100.0  ...     100.0     38.30   23.1594\n",
              "     198      0.0004    0.0000     100.0  ...     100.0     38.44   22.9333\n",
              "     199     -0.0011    0.0003     100.0  ...     100.0     38.29   23.0640\n",
              "     200     -0.0032   -0.0005     100.0  ...     100.0     38.37   23.0522\n",
              "\n",
              "[20631 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPKIQ9ta92z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "45306ef3-a156-4cb6-a961-c812d6dd12f8"
      },
      "source": [
        "data.loc[1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_set_1</th>\n",
              "      <th>op_set_2</th>\n",
              "      <th>op_set_3</th>\n",
              "      <th>sensor1</th>\n",
              "      <th>sensor2</th>\n",
              "      <th>sensor3</th>\n",
              "      <th>sensor4</th>\n",
              "      <th>sensor5</th>\n",
              "      <th>sensor6</th>\n",
              "      <th>sensor7</th>\n",
              "      <th>sensor8</th>\n",
              "      <th>sensor9</th>\n",
              "      <th>sensor10</th>\n",
              "      <th>sensor11</th>\n",
              "      <th>sensor12</th>\n",
              "      <th>sensor13</th>\n",
              "      <th>sensor14</th>\n",
              "      <th>sensor15</th>\n",
              "      <th>sensor16</th>\n",
              "      <th>sensor17</th>\n",
              "      <th>sensor18</th>\n",
              "      <th>sensor19</th>\n",
              "      <th>sensor20</th>\n",
              "      <th>sensor21</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cycle</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>-0.0067</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.75</td>\n",
              "      <td>1602.38</td>\n",
              "      <td>1422.78</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>551.94</td>\n",
              "      <td>2388.31</td>\n",
              "      <td>9037.91</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.00</td>\n",
              "      <td>519.79</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8117.69</td>\n",
              "      <td>8.5207</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.51</td>\n",
              "      <td>22.9588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>-0.0006</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>644.18</td>\n",
              "      <td>1596.17</td>\n",
              "      <td>1428.01</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>550.70</td>\n",
              "      <td>2388.27</td>\n",
              "      <td>9044.55</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.08</td>\n",
              "      <td>519.58</td>\n",
              "      <td>2388.33</td>\n",
              "      <td>8117.51</td>\n",
              "      <td>8.5183</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.48</td>\n",
              "      <td>23.1127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>-0.0027</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.64</td>\n",
              "      <td>1599.22</td>\n",
              "      <td>1425.95</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>551.29</td>\n",
              "      <td>2388.29</td>\n",
              "      <td>9040.58</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.33</td>\n",
              "      <td>520.04</td>\n",
              "      <td>2388.35</td>\n",
              "      <td>8112.58</td>\n",
              "      <td>8.5223</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>23.0675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>-0.0000</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.34</td>\n",
              "      <td>1602.36</td>\n",
              "      <td>1425.77</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>550.92</td>\n",
              "      <td>2388.28</td>\n",
              "      <td>9042.76</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.15</td>\n",
              "      <td>519.57</td>\n",
              "      <td>2388.30</td>\n",
              "      <td>8114.61</td>\n",
              "      <td>8.5174</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.45</td>\n",
              "      <td>23.1295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0.0009</td>\n",
              "      <td>-0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1601.41</td>\n",
              "      <td>1427.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>551.25</td>\n",
              "      <td>2388.32</td>\n",
              "      <td>9033.22</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48.25</td>\n",
              "      <td>520.08</td>\n",
              "      <td>2388.32</td>\n",
              "      <td>8110.93</td>\n",
              "      <td>8.5113</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.48</td>\n",
              "      <td>22.9649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       op_set_1  op_set_2  op_set_3  ...  sensor19  sensor20  sensor21\n",
              "cycle                                ...                              \n",
              "1       -0.0007   -0.0004     100.0  ...     100.0     39.06   23.4190\n",
              "2        0.0019   -0.0003     100.0  ...     100.0     39.00   23.4236\n",
              "3       -0.0043    0.0003     100.0  ...     100.0     38.95   23.3442\n",
              "4        0.0007    0.0000     100.0  ...     100.0     38.88   23.3739\n",
              "5       -0.0019   -0.0002     100.0  ...     100.0     38.90   23.4044\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "188     -0.0067    0.0003     100.0  ...     100.0     38.51   22.9588\n",
              "189     -0.0006    0.0002     100.0  ...     100.0     38.48   23.1127\n",
              "190     -0.0027    0.0001     100.0  ...     100.0     38.49   23.0675\n",
              "191     -0.0000   -0.0004     100.0  ...     100.0     38.45   23.1295\n",
              "192      0.0009   -0.0000     100.0  ...     100.0     38.48   22.9649\n",
              "\n",
              "[192 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7OVKCip05Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqhKjJYcNzQ-",
        "colab_type": "text"
      },
      "source": [
        "## The Predictron Model Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FhCVo6d4xrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MSE\n",
        "\n",
        "class Predictron(tf.keras.Model):\n",
        "  def __init__(self, dataset, RUL, max_depth):\n",
        "    self.inputs = dataset\n",
        "    self.targets = RUL\n",
        "    self.learning_rate = 0.001\n",
        "    self.size = dataset.shape[0]\n",
        "    self.max_depth = max_depth\n",
        "\n",
        "    self.rewards = None\n",
        "    self.gammas = None\n",
        "    self.lambdas = None\n",
        "    self.values = None\n",
        "    self.preturns = None\n",
        "    self.lambda_preturns = None\n",
        "\n",
        "    def build(self):\n",
        "      self.build_model()\n",
        "      self.build_loss()\n",
        "\n",
        "    def iter_func(self, state):\n",
        "      value_net = Flatten(state, 24)\n",
        "      value_net = BatchNormalization(activation='relu')(value_net)\n",
        "      value_net = Dense(1)(value_net)\n",
        "\n",
        "      net = Conv2D(24, (3, 3))(state)\n",
        "      net = BatchNormalization(activation='relu')(net)\n",
        "      flat_net = Flatten()(net)\n",
        "\n",
        "      reward = Dense(24)(flat_net)\n",
        "      reward = BatchNormalization(activation='relu')(reward)\n",
        "      reward = Dense(1)(reward)\n",
        "\n",
        "      gamma = Dense(24)(flat_net)\n",
        "      gamma = BatchNormalization(activation='relu')(gamma)\n",
        "      gamma = Dense(1)(gamma)\n",
        "\n",
        "      lambda_net = Dense(24)(flat_net)\n",
        "      lambda_net = BatchNormalization(activation='relu')(lambda_net)\n",
        "      lambda_net = Dense(1)(lambda_net)\n",
        "\n",
        "      net = Conv2D(24, (3, 3))(net)\n",
        "      net = BatchNormalization(activation='relu')\n",
        "      net = Conv2D(24, (3, 3))(net)\n",
        "      net = BatchNormalization(activation='relu')\n",
        "\n",
        "      return net, reward, gamma, lambda_net, value_net\n",
        "    \n",
        "    def build_model(self):\n",
        "      state = Conv2D(24, (3, 3))(self.inputs)\n",
        "      state = BatchNormalization(activation='relu')(state)\n",
        "      state = Conv2D(24, (3, 3))(state)\n",
        "      state = BatchNormalization(activation='relu')(state)\n",
        "      \n",
        "      iter_template = tf.compat.v1.make_template('iterator', self.iter_func)\n",
        "\n",
        "      rewards_arr = []\n",
        "      gammas_arr = []\n",
        "      lambdas_arr = []\n",
        "      values_arr = []\n",
        "\n",
        "      for k in range(self.max_depth):\n",
        "        state, reward, gamma, lambda_, value = iter_template(state)\n",
        "        rewards_arr.append(reward)\n",
        "        gammas_arr.append(gamma)\n",
        "        lambdas_arr.append(lambda_)\n",
        "        values_arr.append(value)\n",
        "\n",
        "      _, _, _, _, value = iter_template(state)\n",
        "      values_arr.append(value)\n",
        "\n",
        "      bs = tf.shape(self.inputs)[0]\n",
        "      self.rewards = tf.stack(rewards_arr, axis=1)\n",
        "      self.rewards = tf.reshape(self.rewards, [bs, self.max_depth, self.size]) \n",
        "      self.rewards = tf.concat(values=[tf.zeros(shape=[bs, 1, self.size], dtype=tf.float32),\n",
        "                                       self.rewards], axis=1, name='rewards')\n",
        "      self.gammas = tf.stack(gammas_arr, axis=1)\n",
        "      self.gammas = tf.reshape(self.gammas, [bs, self.max_depth, self.size])\n",
        "      self.gammas = tf.concat_v2(values=[tf.ones(shape=[bs, 1, self.size], dtype=tf.float32), self.gammas],\n",
        "                               axis=1, name='gammas')\n",
        "      self.lambdas = tf.stack(lambdas_arr, axis=1)\n",
        "      self.lambdas = tf.reshape(self.lambdas, [-1, self.max_depth, self.size])\n",
        "      self.values = tf.stack(values_arr, axis=1)\n",
        "      self.valeus = tf.reshape(self.values, [-1, (self.max_depth +1), self.size])\n",
        "\n",
        "      self.build_preturns()\n",
        "      self.build_lambda_preturns()\n",
        "\n",
        "    def build_preturns(self):\n",
        "      g_preturns = []\n",
        "      for k in range(self.max_depth, -1, -1):\n",
        "        g_k = self.values[:, k, :]\n",
        "        for kk in range(k, 0, -1):\n",
        "          g_k = self.rewards[:, kk, :] + self.gammas[:, kk, :] * g_k\n",
        "        g_preturns.append(g_k)\n",
        "      g_preturns = g_preturns[::-1]\n",
        "      self.preturns = tf.stack(g_preturns, axis=1, name='preturns')\n",
        "      self.g_preturns = tf.reshape(self.g_preturns, [-1, (self.max_depth + 1), self.size])\n",
        "\n",
        "    def build_lambda_preturns(self):\n",
        "      g_k = self.values[:, -1, :]\n",
        "      for k in range(self.max_depth -1, -1, -1):\n",
        "        g_k = (1 - self.lambdas[:, k, :]) * self.values[:, k, :] + self.lambdas[:, k, :] * (self.rewards[:, k + 1, :] + self.gammas[:, k + 1, :] * g_k)\n",
        "      self.g_lambda_preturns = g_k\n",
        "\n",
        "    def build_loss(self):\n",
        "      self.targets_expanded = tf.expand_dims(self.target, 1)\n",
        "      self.targets_tiled = tf.tile(self.targets_expanded, [1, self.max_depth +1, 1])\n",
        "      self.loss_preturns = MSE(self.g_preturns, self.targets_tiled)\n",
        "      tf.compat.v1.losses.add_loss(self.loss_preturns)\n",
        "      tf.summary.scalar('Loss Preturns', self.loss_preturns)\n",
        "      self.loss_lambda_preturns - MSE(self.g_lambda_preturns, self.targets)\n",
        "      tf.compat.v1.losses.add_loss('Loss Lambda Preturns', self.loss_lambda_preturns)\n",
        "      self.total_loss = losses.get_total_loss(name='Total Loss')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1mAksv0Nuq_",
        "colab_type": "text"
      },
      "source": [
        "## The Training Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpvYgaJBhIdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import six.moves.queue as queue\n",
        "from six.moves import range\n",
        "import datetime\n",
        "import logging\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "# tf.flags.DEFINE_string('train_dir', './ckpts/predictron_train',\n",
        "#                        'dir to save checkpoints and TB logs')\n",
        "# tf.flags.DEFINE_integer('max_steps', 10000000, 'num of batches')\n",
        "# tf.flags.DEFINE_float('learning_rate', 1e-3, 'learning rate')\n",
        "\n",
        "# tf.flags.DEFINE_integer('batch_size', 128, 'batch size')\n",
        "# tf.flags.DEFINE_integer('maze_size', 20, 'size of maze (square)')\n",
        "# tf.flags.DEFINE_float('maze_density', 0.3, 'Maze density')\n",
        "# tf.flags.DEFINE_integer('max_depth', 16, 'maximum model depth')\n",
        "# tf.flags.DEFINE_float('max_grad_norm', 10., 'clip grad norm into this value')\n",
        "# tf.flags.DEFINE_boolean('log_device_placement', False,\n",
        "#                         \"\"\"Whether to log device placement.\"\"\")\n",
        "# tf.flags.DEFINE_integer('num_threads', 10, 'num of threads used to generate mazes.')\n",
        "\n",
        "train_dir = '/'\n",
        "max_steps = 10000\n",
        "learning_rate = 0.0001\n",
        "batch_size = 32\n",
        "# define 'size' after dataframe import\n",
        "max_depth = 4\n",
        "max_grad_norm = 10.\n",
        "log_device_placement = False\n",
        "\n",
        "\n",
        "# logging.basicConfig()\n",
        "# logger = logging.getLogger('training')\n",
        "# logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "def train():\n",
        "  # config = FLAGS\n",
        "\n",
        "  # global_step = tf.get_variable(\n",
        "  #   'global_step', [],\n",
        "  #   initializer=tf.constant_initializer(0), trainable=False)\n",
        "\n",
        "  cmapss_df = None\n",
        "  rul_lables = None\n",
        "\n",
        "  model = Predictron(cmapss_df, rul_lables, max_depth)\n",
        "  model.build()\n",
        "\n",
        "  loss = model.total_loss\n",
        "  loss_preturns = model.loss_preturns\n",
        "  loss_lambda_preturns = model.loss_lambda_preturns\n",
        "\n",
        "  opt = tf.keras.AdamOptimizer(learning_rate=learning_rate)\n",
        "  grad_vars = opt.get_gradients(loss, tf.trainable_variables())\n",
        "  grads, vars = zip(*grad_vars)\n",
        "  grads_clipped, _ = tf.clip_by_global_norm(grads, FLAGS.max_grad_norm)\n",
        "  grad_vars = zip(grads_clipped, vars)\n",
        "  apply_gradient_op = opt.apply_gradients(grad_vars, global_step=global_step)\n",
        "\n",
        "  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "  update_op = tf.group(*update_ops)\n",
        "  # Group all updates to into a single train op.\n",
        "  train_op = tf.group(apply_gradient_op, update_op)\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "  sess = tf.Session()\n",
        "  sess.run(init)\n",
        "\n",
        "  saver = tf.train.Saver(tf.global_variables())\n",
        "  tf.train.start_queue_runners(sess=sess)\n",
        "\n",
        "  train_dir = os.path.join(FLAGS.train_dir, 'max_steps_{}'.format(FLAGS.max_depth))\n",
        "  summary_merged = tf.summary.merge_all()\n",
        "  summary_writer = tf.summary.FileWriter(train_dir, sess.graph)\n",
        "\n",
        "  frame_queue = queue.Queue(100)\n",
        "\n",
        "  def \n",
        "\n",
        "  def maze_generator():\n",
        "    col_names = ['unit', 'cycle', 'op_set_1', 'op_set_2', 'op_set_3',\n",
        "             'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6',\n",
        "             'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12', \n",
        "             'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17',\n",
        "             'sensor18', 'sensor19', 'sensor20', 'sensor21']\n",
        "\n",
        "    data = pd.read_csv('train_FD001.txt',\n",
        "                      delimiter=' ',\n",
        "                      names=col_names,\n",
        "                      index_col=False,\n",
        "                      skipinitialspace=True\n",
        "                      )\n",
        "\n",
        "    data.set_index(['unit', 'cycle'], inplace=True)\n",
        "    \n",
        "\n",
        "\n",
        "  for thread_i in range(FLAGS.num_threads):\n",
        "    t = threading.Thread(target=maze_generator)\n",
        "    t.start()\n",
        "\n",
        "  for step in range(FLAGS.max_steps):\n",
        "    start_time = time.time()\n",
        "    maze_ims_np, maze_labels_np = frame_queue.get()\n",
        "\n",
        "    _, loss_value, loss_preturns_val, loss_lambda_preturns_val, summary_str = sess.run(\n",
        "      [train_op, loss, loss_preturns, loss_lambda_preturns, summary_merged],\n",
        "      feed_dict={\n",
        "        maze_ims_ph: maze_ims_np,\n",
        "        maze_labels_ph: maze_labels_np\n",
        "      })\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
        "\n",
        "    if step % 10 == 0:\n",
        "      num_examples_per_step = FLAGS.batch_size\n",
        "      examples_per_sec = num_examples_per_step / duration\n",
        "      sec_per_batch = duration\n",
        "\n",
        "      format_str = (\n",
        "        '%s: step %d, loss = %.4f, loss_preturns = %.4f, loss_lambda_preturns = %.4f (%.1f examples/sec; %.3f '\n",
        "        'sec/batch)')\n",
        "      logger.info(format_str % (datetime.datetime.now(), step, loss_value, loss_preturns_val, loss_lambda_preturns_val,\n",
        "                                examples_per_sec, sec_per_batch))\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      summary_writer.add_summary(summary_str, step)\n",
        "\n",
        "    # Save the model checkpoint periodically.\n",
        "    if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n",
        "      checkpoint_path = os.path.join(train_dir, 'model.ckpt')\n",
        "      saver.save(sess, checkpoint_path, global_step=step)\n",
        "\n",
        "\n",
        "def main(argv=None):\n",
        "  train()\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agDe5MGxEAmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}